*Нужно понять контекст сущности чтобы определить кто это по сути, а далее проверять этот контекст, в случае если видим что-то напоминающее нашу сущность, дабы установить, что речь идёт именно о ней*

- **Что такое "Сущность"?**  
    Любой объект, о котором есть данные: человек ("Иван Иванов"), компания ("Яндекс"), город ("Киров"), событие ("Олимпиада 2024"). Важно: в разных источниках сущность может называться по-разному ("Иван", "Иванов И.И.", "Ваня")

Сравнивать дополнительные атрибуты сущности (email, телефон, геолокацию)

**NER:** - детектор сущностей. Он только **называет типы** (человек/компания/город), но не понимает, _кто именно_ это.

**NER (Named Entity Recognition)** — процесс выделения сущностей в тексте: людей, организаций, мест, дат и т.д. Например, в предложении *«Марк работал в Google»* NER найдёт *«Марк»* (персона) и *«Google»* (организация).

---

**NEL** Опирается на контекст и Базы знаний (Wikipedia)

**NEL (Named Entity Linking)** — После выделения сущностей NEL связывает их с уникальными идентификаторами в базе знаний *(KB)*. Например, слово *«Apple»* может быть ссылкой на компанию Apple Inc. (через Wikipedia/DBpedia) или на фрукт — NEL решает, какой вариант подходит по контексту . 

[TagMe](https://tagme.d4science.org/tagme/)
![[Pasted image 20250709134712.png]]

| Этап | Задача                     | Инструмент                                                                   |
| ---- | -------------------------- | ---------------------------------------------------------------------------- |
| NER  | Найти сущности в тексте    | [bert-base-NER](https://huggingface.co/dslim/bert-base-NER)                  |
| NEL  | Указать, что это за объект | [TagMe](https://tagme.d4science.org/tagme/)  [Wikifier](http://wikifier.org) |


## Альтернативы:

NER:

| Метод                             | Описание                                                       | Плюсы                                   | Минусы                                                                                                                   |
| --------------------------------- | -------------------------------------------------------------- | --------------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| **Регулярные выражения**          | Поиск шаблонов в тексте (например, даты, телефоны)             | Простота, быстро, не требует обучения   | Не подходит для сложных сущностей (например: "Министерство науки и высшего образования РФ"), не умеет различать контекст |
| **Словари / газеттиры**           | Поиск в заранее заданных списках слов                          | Простота, контроль                      | Не находит новые имена, проблемы с омонимами                                                                             |
| **Правила (экспертные)**          | Ручные лингвистические правила: шаблоны + грамматика           | Контроль, Интерпретируемость            | Сложно масштабировать, не обрабатывает вариации языка                                                                    |
| **CRF (Условные случайные поля)** | Модель с ручными признаками и контекстной зависимостью         | Гибкая, большая точность                | Требует разметки, Сложнее реализовать                                                                                    |
| **biLSTM-CRF**                    | Двунаправленные нейросети + CRF для NER                        | Большая точность                        | Долгое обучение, Требует GPU и разметки                                                                                  |
| **Transformers (BERT, RoBERTa)**  | Современные модели, учитывающие глобальный контекст            | Мультиязычность                         | Требует ресурсы, Трудности интерпретации                                                                                 |
| **LLM (GPT‑4, LLaMA)**            | Модель "по запросу": "Найди всех людей и организации в тексте" | Без обучения, гибкость, мультиязычность | **Галлюцинации**                                                                                                         |
| **Гибридные методы**              | Комбинация: шаблоны + словари + DL                             | Универсальность, большая точность       | Сложность архитектуры, cложнее поддерживать                                                                              |
NEL:

| Метод                                     | Описание                                                               | Плюсы                                                | Минусы                                                            |
| ----------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------- | ----------------------------------------------------------------- |
| **Простое соответствие (lookup)**         | Поиск в базе по совпадению имени (label/alias)                         | Быстро, просто, Применимо для больших баз (Wikidata) | Не работает при опечатках, много кандидатов с одинаковыми именами |
| **Словарь с ручной аннотацией**           | Каждое упоминание связано вручную                                      | Высокая точность, Контроль                           | Невозможно масштабировать, работа ручками                         |
| **ML‑ранжировщик (BERT + классификатор)** | Обучаем классификатор, который выбирает лучшего кандидата по контексту | Высокая точность, Учитывает контекст + meta          | Требует обучающей выборки, дорого                                 |
| **Пороговая фильтрация + популярность**   | Отбираем топ‑к кандидатов, учитывая частоту ссылок                     | Быстро, просто                                       | Ошибки при редких именах                                          |
| **LLM**                                   | Генеративная модель сама решает, к чему относится сущность             | Быстро, мультиязычность                              | **Галлюцинации**                                                  |
| **Графовые подходы (Knowledge graph)**    | Используем граф знаний: узлы – сущности, связи – отношения             | Рассуждения, контекст                                | Сложно, требует чистую онтологию (аккуратная база знаний)         |
**Варианты замены на LLM:**  
- Задача требует генерации текста или работы с неструктурированными данными  
- Сложная задача, где KB недостаточно (перевод текста с редкими именами)  

**Алгоритмы NEL**:  
  - **AIDA**: использует статистику из Wikipedia для связывания сущностей
  - **BLINK**: использует BERT для контекстного представления сущностей (более современный подход)

**Инструменты**:  
  - **spaCy** (Python): для NER и простого NEL  
  - **Stanford NLP**: мультиязычность  
  - **OpenTapioca**: связывание с Wikidata  

## Примерный план:

![[Pasted image 20250709131834.png]]

 1. NER для извлечения сущностей  
  Используем готовое (например, spaCy, Natasha для русского языка) или обучите свои на специфических терминах (например, названиях патентов или научных терминах)

2. Связывание через KB (Базу знаний)    
  - **Wikipedia/DBpedia**: для общих сущностей
  - **Wikidata**: содержит уникальные ID и связи между сущностями
  - **YAGO**: связывает сущности с фактами из Википедии и WordNet
  - **Специализированные KB**. 

3. Контекст  
  - **Контекст предложения**: **"Java"** в контексте *"язык программирования"* => ссылка на Java (язык), а не на остров  
  - **Статистика из KB**: популярные сущности в определённой области (например, в патентах чаще встречаются компании, а не природные объекты)

4. Формирование истории объекта
  Для отслеживания эволюции сущности во времени:  
  - **Временные метки**: извлечение даты (NER).
  - **Граф связей**: построение графика с сущностями и связями между ними во времени
  - **Пример**: связь между компанией и её технологией из патента 2010 года, а затем упоминание этой технологии в научной статье 2020 года

## Эксперименты:

**Подготовка тестовой базы**

Можно взять **свою мини-базу знаний** (CSV или словарь), например:

```python
# Простая база: две сущности
my_kb = [
    {"id": "Q1", "name": "Владимир Путин", "description": "Президент России"},
    {"id": "Q2", "name": "Москва", "description": "Столица России"}
]
```

```python
import spacy

nlp = spacy.load("en_core_web_sm")

entity_kb = {
    "Vladimir Putin": {
        "description": "Russian politician, President of Russia.",
        "wikipedia": "https://en.wikipedia.org/wiki/Vladimir_Putin"
    }
}

def perform_ner(text):
    doc = nlp(text)
    print("=== NER ===")
    for ent in doc.ents:
        print(f"Entity: {ent.text}, Label: {ent.label_}")
    return [(ent.text, ent.label_) for ent in doc.ents]

def perform_nel(entities):
    print("=== NEL (Entity Linking) ===")
    for name, label in entities:
        if name in entity_kb:
            info = entity_kb[name]
            print(f"Entity: {name}")
            print(f"  Description: {info['description']}")
            print(f"  Wikipedia: {info['wikipedia']}")
        else:
            print(f"Entity: {name} - no link found")

# Тесты
text1 = "Hi John and Vladimir"
text2 = "Hi John and Vladimir Putin"

ner_entities_1 = perform_ner(text1)
perform_nel(ner_entities_1)

print("\n")

ner_entities_2 = perform_ner(text2)
perform_nel(ner_entities_2)

```


``` python
import spacy  
from kb import entity_kb  
  
nlp = spacy.load("en_core_web_sm")  
  
# Автоиндекс  
name_to_id = {v["name"]: k for k, v in entity_kb.items()}  
  
def perform_ner(text):  
    doc = nlp(text)  
    print("=== NER ===")  
    entities = [(ent.text, ent.label_) for ent in doc.ents]  
    for ent_text, label in entities:  
        print(f"Entity: {ent_text}, Label: {label}")  
    return entities  
  
def resolve_entity_id(name):  
    return name_to_id.get(name)  
  
def show_entity_info_by_id(ent_id, visited=None, level=0):  
    if visited is None:  
        visited = set()  
    if ent_id in visited:  
        return  
    visited.add(ent_id)  
  
    entity = entity_kb[ent_id]  
    indent = "  " * level  
    print(f"{indent}Entity: {entity['name']}")  
    print(f"{indent}  Description: {entity['description']}")  
    print(f"{indent}  Wikipedia: {entity['wikipedia']}")  
  
    for linked_id in entity.get("linked", []):  
        if linked_id in entity_kb:  
            show_entity_info_by_id(linked_id, visited, level + 1)  
  
def perform_nel(entities):  
    print("=== NEL (Entity Linking) ===")  
    for name, label in entities:  
        ent_id = resolve_entity_id(name)  
        if ent_id:  
            show_entity_info_by_id(ent_id)  
        else:  
            print(f"Entity: {name} - no link found")  
  
  
text = "Elon Musk and Vladimir Putin met in the USA"  
  
print("="*50)  
print(text)  
print("="*50)  
entities = perform_ner(text)  
perform_nel(entities)
```


## Проблемы модели:

### Ошибки NER

#### 1. `en_core_web_sm` — **маленькая модель**

- Она не содержит word vectors (векторов слов);
    
- Использует только правила и небольшое количество статистики;
    
- Соответственно, **часто ошибается на реальных текстах**.
    

#### 2. `n't` (часть от **"didn't"**) ошибочно выделяется как сущность

Модель может **ошибочно воспринять `n't` как аббревиатуру страны** или что-то подобное.


### Контекст:

Модель `spaCy` в нашем коде _пытается_ учитывать контекст, но **не очень глубоко**, особенно если используется `en_core_web_sm`.

Модель смотрит на соседние слова. Например:

```
1. "Apple released a new iPhone" → ORG (компания)
2. "I ate an apple for lunch"    → FRUIT (не будет определено как сущность вообще)
```
Модель видит глагол "released" + "iPhone" и делает вывод, что это **компания**.  
Во втором случае "ate" и "lunch" → значит **фрукт**.

#### Контекст учитывается **на поверхности**.

Маленькие модели (`en_core_web_sm`) работают не на глубоком контексте, а на:

- POS-тегах
    
- шаблонах
    
- поверхностной статистике
    

Это значит, что в более сложных случаях они ошибаются:

```
"Steve Jobs founded Apple." → ОК  
"He threw the apple at the wall." → ОК  
"But: 'Apple was delicious today.' → может ошибиться и выдать ORG

```
